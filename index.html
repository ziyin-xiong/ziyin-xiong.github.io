<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <title>Ziyin Xiong</title>

    <meta name="author" content="Ziyin Xiong 熊梓因" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" href="images/bear.png" type="image/x-icon" />
    <link rel="stylesheet" type="text/css" href="stylesheet.css" />
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center; font-weight: normal; font-size: 25px;">
                  Ziyin Xiong&nbsp;&nbsp;|&nbsp;&nbsp;熊梓因
                </p>
                <p>I am a senior undergraduate student at <a href="https://tongclass.ac.cn/">Tong Class</a> (founded and led by Professor <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a>) in <a href="https://yuanpei.pku.edu.cn/en/">Yuanpei College</a>, <a href="https://english.pku.edu.cn/">Peking University</a>, majoring in Artificial Intelligence.
                </p>
                <p>
                  At Peking University, I am advised by Prof. <a href="https://yzhu.io/">Yixin Zhu</a>. In 2023 fall, I visited <a href="https://me.berkeley.edu/">UC Berkeley</a> and was honored to be advised by Prof. <a href="https://msc.berkeley.edu/people/tomizuka.html">Masayoshi Tomizuka</a>. Currently, I collaborate with Dr. <a href="https://siyuanhuang.com/">Siyuan Huang</a> and Dr. <a href="https://tengyu.ai/">Tengyu Liu</a> at the General Vision Lab in <a href="https://eng.bigai.ai/">BIGAI</a>. Previously, I had the privilege to work with Prof. <a href="https://cfcs.pku.edu.cn/english/people/faculty/xiaotiedeng/index.htm">Xiaotie Deng</a> and Prof. <a href="https://cfcs.pku.edu.cn/yuqkong/">Yuqing Kong</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:xiongziyin@stu.pku.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/ZiyinXiong-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/ziyin-xiong/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ziyin-xiong/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:35%;max-width:35%">
                <a href="images/zyxiong.jpg"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/zyxiong.jpg"></a>
              </td>
            </tr>
          </tbody></table>
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle;font-size:medium;">
                <p style="text-decoration:underline;text-decoration-color:#20B2AA;font-size:25px;">Research Interest</p>
                <p>
                  My research goal is to develop generalizable robot skill learning and equip robots with the ability to reason and solve complex tasks in a manner similar to that of humans. I am especially interested in the intersection of robot learning, robot vision, and reinforcement learning.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
                <p style="text-indent:20px;text-decoration:underline;text-decoration-color:#20B2AA;font-size:25px;">Selected Papers</p>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
      <td style="padding: 20px; width: 25%; vertical-align: middle; text-align: center;"><img src="images/ag2x2.png" width=100%></td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ziyin-xiong.github.io/ag2x2.github.io/">
          <span class="papertitle">Ag2x2: A Robust Agent-Agnostic Visual Representation Boosts Zero-Shot Learning of Bimanual Robotic Manipulation</span>
        </a>
        <br>
		<strong>Ziyin Xiong*</strong>,
		Yinghan Chen*,
		<a href="https://xiaoyao-li.github.io/" style="color:#000000;">Puhao Li</a>,
		<a href="https://yzhu.io/" style="color:#000000;">Yixin Zhu</a>,
		<a href="https://tengyu.ai/" style="color:#000000;">Tengyu Liu</a>,
        	<a href="https://siyuanhuang.com/" style="color:#000000;">Siyuan Huang</a>
        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="TODO: paper link">Paper</a>
	/
        <a href="https://ziyin-xiong.github.io/ag2x2.github.io/">Project</a>
        /
        <a href="https://github.com/ziyin-xiong/Ag2x2">Code</a>
        <p></p>
        <p>
        We present Ag2x2, a framework that advances the autonomous acquisition of bimanual manipulation skills through agent-agnostic and coordination-aware visual representations that jointly encode object and hand motion patterns.
        </p>
      </td>
    </tr>
	  </tbody></table>
		  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align：center;font-size:small;">
                  Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
